# Module 3: Managing Datasets
# Lab: Managing datasets

### Scenario
You work as a data scientist for Adatum Consultants, a company that provides machine learning services and advice for a range of clients. One of your clients is Wide World Importers, who are transitioning from a Business Intelligence practice to a Business Analytics practice. As part of this transition, Wide World Importers are looking for insights from operational data sources throughout the organization.
You are working with a team of business analysts from Wide World Importers, who write reports using data that is stored in a variety of locations, including flat files, Azure Blob storage, and Azure SQL Database. You will be using Machine Learning with this team so, to familiarize yourself with this environment, you should explore the steps required in Azure Machine Learning Studio to import data and to manage datasets.

### Objectives
After completing this lab, you will be able to:
-   Import data into Machine Learning.
-   Convert imported data into separate datasets

### Lab Setup
- **Estimated Time**: 60 Minutes
- **Virtual machine**: 20774A-LON-DEV
- **User name**: ADATUM\\AdatumAdmin
- **Password**: Pa55w.rd

## Exercise 1: Preparing the lab

### Scenario
Before you can start using Machine Learning with your clients, you need to create an example Azure SQL Database. In this exercise, you will create a database, and import sample data into this database.

The main tasks for this exercise are as follows:
1. Create Azure SQL Database
2. Import data into Azure SQL Database

#### Task 0: Update SQL Server Management Server and Tools
**IMPORTANT**. Recent changes to Azure SQL Database are incompatible with the version of SQL Server Management Studio and tools such as sqlpackage installed on the **20774A-LON-DEV** virtual machine. Before commencing this exercise, login in to the **20774A-LON-DEV** virtual machine as **ADATUM\\AdatumAdmin**, open the web browser, move to the URL **https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms**, and then download and install the latest build of SQL Server Management Studio.

#### Task 1: Create Azure SQL Database
1. Log on to **20774A-LON-DEV** virtual machine as **ADATUM\\AdatumAdmin**.
2. In Internet Explorer, browse to the Azure portal and sign in with your Azure account.
3. Create a new SQL Database called **WideWorldImporters-Standard**, using a new resource group called **&lt;yourname&gt;rg**, using a blank database source.
4. Call the server name **&lt;yourname&gt;&lt;date&gt;**, create a login called dbadmin with a password of **Pa55w.rd** in your local region.
5. Select a standard pricing tier with a DTU of **10(S0)**.
6. Note the database and server names you created.
7. Wait for the successful deployment message.
8. On the database blade, change the Firewall settings to add your current client IP address to the list of allowed IP addresses.

#### Task 2: Import data into Azure SQL Database
1. On the **20774A-LON-DEV** virtual machine, extract the **E:\\Labfiles\\Lab03\\WideWorldImporters-Standard.part1.exe**.
2. Start a command prompt with administrative rights.
3. Change to the **C:\\Program Files (x86)\\Microsoft SQL Server\\140\\DAC\\Bin** folder.
4. Run the command in **E:\\Labfiles\\Lab03\\SqlPackageCmd.txt**.
5. When you have imported the database successfully, close the command prompt.

**Results:** At the end of this exercise, you will have created an Azure SQL Database, and imported WideWorldImporters-Standard data into this database.

## Exercise 2: Importing data into Machine Learning

### Scenario
Before you can start using Machine Learning for data import with your clients, you should understand how the import process works for different types of data. In this exercise, you will import data from a flat file, update an existing dataset, load data into Azure Blob storage, and load data from Azure SQL Database.

The main tasks for this exercise are as follows:
1. Import data from a flat file
2. Update an existing dataset
3. Prepare Azure Blob storage
4. Import data from Azure Blob storage
5. Prepare the Azure SQL Database
6. Import data from the Azure SQL Database

#### Task 1: Import data from a flat file
1. Log on to the **20774A-LON-DEV** virtual machine as **ADATUM\\AdatumAdmin**.
2. In Internet Explorer, browse to **https://studio.azureml.net/** and sign in with your Microsoft account.
3. Create a new dataset from a local file.
4. Upload **E:\\Labfiles\\Lab03\\DimDate.csv** as the **Date Dimensions dataset** using a generic CSV file with no header.

#### Task 2: Update an existing dataset
1. In Microsoft Azure Machine Learning Studio, create a new dataset and import **E:\\Labfiles\\Lab03\\DimDate2.csv**.
2. Use this import to replace the data in the **Date Dimensions** dataset. Select the same format type as earlier.

#### Task 3: Prepare Azure Blob storage
1. Browse to the Azure portal and sign in with your Azure credentials.
2. Create a new storage account with the name **&lt;yourname&gt;&lt;date&gt;.core.windows.net**, using the storage group you created earlier. Note the name of storage that you create.
3. Wait until the deployment is successful.
4. On the Access Keys settings on your new storage account, copy **key1 Key**.
5. Switch to Azure Storage Explorer and sign in with your Azure account setting, using your Learning Pass subscription credentials. Select all options on login.
6. Connect to the Azure storage using the storage account name and key from the previous section.
7. In Azure Storage Explorer, create a new blob container called **training**.
8. Upload **C:\\Labfiles\\Lab03\\DimDate.csv** to that new container.
9. Wait until uploading has completed before closing Microsoft Azure and continuing.

#### Task 4: Import data from Azure Blob storage
1. Switch to Microsoft Azure Machine Learning Studio and create a new blank experiment.
2. Add the **Import Data** task to the canvas.
3. Configure **Azure Blob Storage** as the data source and **Storage Account** as the authentication type.
4. Connect to the storage account you created earlier, using the storage access key that you previously copied.
5. Specify **training/DimDate.csv** as the path, CSV with encoding as the **Blob file format**, and specify to use cached results.
6. Run the experiment.
7. When the experiment completes, save the experiment as **Import Data into Azure ML**.

#### Task 5: Prepare the Azure SQL Database
1. Switch back to the Azure portal and under **All Resources**, select **WideWorldImporters-Standard**.
2. Log in to the Data Explorer, using SQL Server authentication with a user name of **dbadmin** and password of **Pa55w.rd**.
3. Run the command from **E:\\Labfiles\\Lab03\\SqlSchemaCmd.txt**.
4. Delete the command and run the command from **E:\\Labfiles\\Lab03\\SqlViewCmd.txt**.

#### Task 6: Import data from the Azure SQL Database
1. In Microsoft Azure Machine Learning Studio, add a second instance of the **Import Data** module to your experiment.
2. Configure the properties to use the **&lt;your db servername&gt;.database.windows.net** Azure SQL Database server name, and the Database name of **WideWorldImporters-Standard**.
3. Enter the server user account name and password.
4. Run the following query:
    ```
	SELECT * From [20774A].[CustomerTransactions]
    ```
5. Select **Use cached results**, then run the experiment.
6. When the experiment completes, click **Save**.

**Results:** At the end of this exercise, you will have imported data from a flat file, updated an existing dataset, loaded data into blob storage, prepared an Azure SQL database, and loaded data from that database to Machine Learning.

## Exercise 3: Converting imported data into separate datasets

### Scenario
Before you can start using Machine Learning for data import with your clients, you need to understand how to split imported data into training and test datasets. In this exercise, you will first visualize imported data, then split this data, and confirm that the split has been successful.

The main tasks for this exercise are as follows:
1. Visualize imported data
2. Split imported data into separate datasets
3. Confirm creation of split datasets

#### Task 1: Visualize imported data
1. Visualize the imported data from the Azure Blob.
2. Click a column to view a histogram of the data.
3. Visualize the data from the Import Data module.
4. Note that this data has 5 columns and **97,547** rows.
5. Click **TaxAmount** to see the data distribution.
6. Summarize and view the imported data from Azure SQL Database.
7. Connect **Summarize Data** to **Import Data**.
8. Run the experiment.
9. Visualize the data and note that, from the 97,547 rows in the original data, there are now 5 rows and 23 columns.
10. Save the experiment.

#### Task 2: Split imported data into separate datasets
1. In Machine Learning, switch to the **Import Data into Azure ML** experiment.
2. Drag the **Split Data** task on to the canvas.
3. Connect the **Split Data** task to the **Import Data** task.
4. In the properties of **Split Data**, configure **Fraction of rows in the output dataset** to **0.7**.
5. Drag the **Convert to Dataset** task on to the canvas.
6. Connect the input port on **Convert to Dataset** to the left-hand output port on **Split Data**.
7. Duplicate the **Convert to Dataset** task on to the canvas.
8. Connect the input port on **Convert to Dataset** to the right-hand output port on **Split Data**.
9. Run the experiment.
10. You will now have two **Convert to Dataset** tasks, one with 70 percent of the data, and the other with 30 percent.

#### Task 3: Confirm creation of split datasets
1. When the experiment in the previous task has completed, use the left-hand **Convert to Dataset** module to visualize the data. Note the number of rows.
2. Repeat this process with the right-hand **Convert to Dataset** module. Note the number of rows.
3. Check that one module has 70 percent of the initial dataset and the other has 30 percent.
4. Save the experiment and close Internet Explorer.

**Results:** After this exercise, you will have visualized some imported data, split this data into two datasets, and then confirmed that the split has been successful.

**Question:** How much data should you use for training?

**Question:** When might the use of cached data not be a good idea?

©2017 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
